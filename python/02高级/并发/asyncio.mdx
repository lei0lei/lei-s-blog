---
title: asyncio
slug: /python/thread/asyncio
sidebar_position: 3
---

https://realpython.com/async-io-python/

本文包含:
- async IO, 很多编程语言实现的非语言范式
- async/await, python中定义coroutine的两个关键字
- asyncio, python中运行和管理coroutine的基础和API

asyncio相比multiprocessing和threading没那么出名,因此首先对几个概念进行以下对比。

parallelism意思是同时运行多个操作,multiprocessing是其实现的一种方式,将多个task分发给多个
cpu(物理上或者多个核心),这很适合cpu受限的任务:在实际中会和for循环和数学操作联系紧密。

concurrenct比parallelism概念上更加宽泛,多个task是以重叠的行为进行运行的。

threading是一种cocurrent模型,多个thread轮流执行task.一个进程可以包含多个threads.由于GIL
的存在python的线程会更加复杂。关于线程,需要知道的是这是用于IO受限的任务。CPU受限表示需要cpu的
核从开始到结束一直工作,IO受限表示需要在等待I/O完成上花费时间。

总之cocurrency包含了多进程和线程,多进程是parallelism的一种形式或者说特殊情况。python通过
标准库中的multiprocessing,threading和cocurrent.futures包来提供这些概念的支持。

经过了一些发展,一种设计被融合进了CPython:async IO,这个概念在其他的如Go,c#和Scala中也有存在。
asyncio既不是threading也不是multiprocessing,而且也不构建在两者之上。

asyncio是单线程单进程的设计:使用的是cooperative multitasking。asyncio会在单线程单进程上营造
出cocurrency的感觉,coroutine可以并发的被调度但是本身不是并发。asyncio更接近于threading而不是
multiprocess但是跟两者都有很大不同。

asynchronous很难做一个精准的定义,但是可以有两个特点来辅助理解:
- 异步的routine可以在等待结果的时候进行pause同时让其他routine继续运行
- 异步的代码可以营造出并发的感觉。


:::tip
2017 pycon上 Miguel Grinberg有一个对异步的解释:

象棋大师Judit举办了一个象棋比赛,1Vn,他可以有两种方式进行比赛:同步方式和异步方式。


假设Judit有24个对手,Judit每下一步棋花5秒,对手花55秒,平均每个完局需要双方各30步。

- 同步版本: Judit一次打一个对手直达游戏结束,每个游戏要花(55+5)*30=1800s,总共要12h.
- 异步版本: Judit一桌一桌的打,在一桌上下一步棋,挪到第二桌再下一步,24个对手都走完一步
要24*5=120s,总共要1h.

类似的,asyncio将需要长的等待时间的函数进行阻塞并让其他函数执行。python的异步概念是构建在回调,事件,
transports,protocol,future之上的,并不是很容易理解和使用,asyncio终究提供了一个方便的方式。

:::

## asyncio包和`async/await`

python的asyncio包与关键字async和 await可以一起用来帮助我们声明构建执行和管理异步代码。
### async/await语法和原生coroutines

:::note
python的async从3.4之后才发展起来,使用之后的python版本。
:::

asyncio的核心是coroutine. coroutine是一种特殊版本的generator函数。coroutine是
这样一种函数,在到达return之前就可以终止执行然后间接的把控制传递给另一个coroutine一段
时间。

之后我们会更深入的看传统的生成器如何实现coroutine的。

下面是一些asyncio代码,展示了其核心功能:

```py
#!/usr/bin/env python3
# countasync.py

import asyncio

async def count():
    print("One")
    await asyncio.sleep(1)
    print("Two")

async def main():
    await asyncio.gather(count(), count(), count())

if __name__ == "__main__":
    import time
    s = time.perf_counter()
    asyncio.run(main())
    elapsed = time.perf_counter() - s
    print(f"{__file__} executed in {elapsed:0.2f} seconds.")
```

```py
$ python3 countasync.py
One
One
One
Two
Two
Two
countasync.py executed in 1.01 seconds.
```
注意输出的顺序,每个count的调用都是单独的事件循环或者叫coordinator.当每个任务到达
`await asyncio.sleep(1)`,函数都会告诉事件循环并且把控制交给事件循环。

和同步版本的对比:
```py
#!/usr/bin/env python3
# countsync.py

import time

def count():
    print("One")
    time.sleep(1)
    print("Two")

def main():
    for _ in range(3):
        count()

if __name__ == "__main__":
    s = time.perf_counter()
    main()
    elapsed = time.perf_counter() - s
    print(f"{__file__} executed in {elapsed:0.2f} seconds.")
```

```
$ python3 countsync.py
One
Two
One
Two
One
Two
countsync.py executed in 3.01 seconds.
```

尽管使用time.sleep()和asyncio.sleep()看上去比较普通，他们可以替换需要运行一段时间的过程。
time.sleep()可以表示需要消耗时间的导致函数阻塞的调用,asyncio.sleep()用来表示非阻塞的调用。

await某个东西的好处是包裹的函数可以临时移交控制给另一个函数来立刻开始某件事。但是time.sleep()
或者其他阻塞类型的调用会阻止其他的调用。

之后我们会看到await的优点, 用await的函数可以临时把控制给另一个函数做其他的事,而同步代码则是
阻止所有的运行。

### Asyncio的规则
现在看一下更正式的async,await和coroutine函数的定义。
- async def 引入了native coroutine或者asynchronous generator. async with 和async for 也是有效的。
- await将函数控制权交还给事件循环，暂停函数的执行。如果python在g()的作用域内发现了一个await f(),await 
就会告诉事件循环，暂停g()的运行直到等待的f()的结果被返回，同时让其他的工作运行。

第二点看起来就像:
```py
async def g():
    # Pause here and come back to g() when f() is ready
    r = await f()
    return r
```
关于何时以及如何使用或者不适用async/await 有一套严格的规则。
- async def引入的函数是coroutine.可能会使用await,return,yield.但这都是可选的，
生命async def Noop(): pass也是有效的。
    - 使用await 和/或者return 会创建一个coroutine函数，要调用coroutine函数需要
    await来得到其结果。
    - 在async def 块中使用yield不是很常见，但是合法。这会创建一个asynchronous generator
    可以使用async for 来迭代。让我们先忽略async generator 集中于使用coroutine函数。
    - 使用async def 定义的任何东西都不要使用yield from ,这回导致语法错误。

- 在def函数之外使用yield会导致语法错误，类似的，在async def外面使用await也会导致语法错误。

下面是上述规则的总结:
```py
async def f(x):
    y = await z(x)  # OK - `await` and `return` allowed in coroutines
    return y

async def g(x):
    yield x  # OK - this is an async generator

async def m(x):
    yield from gen(x)  # No - SyntaxError

def m(x):
    y = await z(x)  # Still no - SyntaxError (no `async def` here)
    return y
```
在使用await f()的时候，f()必须是awaitable的对象，目前只要知道awaitable的对象或者是
另一个coroutine或者是定义了.__await__()方法可以返回iterator的对象。在写程序的时候
只需要担心第一种。

有的时候可能会看到旧的将函数变为协程的语法`@asyncio.coroutine`，这是基于生成器的协程。
这与基于原生协程的方法相同，并且会在3.10移除。

```py
import asyncio

@asyncio.coroutine
def py34_coro():
    """Generator-based coroutine, older syntax"""
    yield from stuff()

async def py35_coro():
    """Native coroutine, modern syntax"""
    await stuff()
```

在后面的内容我们会用基于生成器的协程来解释协程，async/await 就是把协程作为单独的python特征
而不是生成器函数来减少不确定性。

这里有一个显示asyncio减少等待时间的例子:给定一个coroutine makeradom()一直产生[0,10]范围内的随机
整数。我们想要对该cotoutine的调用不需要互相等待:

```py
#!/usr/bin/env python3
# rand.py

import asyncio
import random

# ANSI colors
c = (
    "\033[0m",   # End of color
    "\033[36m",  # Cyan
    "\033[91m",  # Red
    "\033[35m",  # Magenta
)

async def makerandom(idx: int, threshold: int = 6) -> int:
    print(c[idx + 1] + f"Initiated makerandom({idx}).")
    i = random.randint(0, 10)
    while i <= threshold:
        print(c[idx + 1] + f"makerandom({idx}) == {i} too low; retrying.")
        await asyncio.sleep(idx + 1)
        i = random.randint(0, 10)
    print(c[idx + 1] + f"---> Finished: makerandom({idx}) == {i}" + c[0])
    return i

async def main():
    res = await asyncio.gather(*(makerandom(i, 10 - i - 1) for i in range(3)))
    return res

if __name__ == "__main__":
    random.seed(444)
    r1, r2, r3 = asyncio.run(main())
    print()
    print(f"r1: {r1}, r2: {r2}, r3: {r3}")
```
<p align="center">
<img src="https://realpython.com/cdn-cgi/image/width=300,format=auto/https://files.realpython.com/media/asyncio-rand.dffdd83b4256.gif
" alt="win" width="400"/>
</p>

这个程序使用一个主coroutine,makerandom()然后在3个不同的输入中并行的运行。大多数程序都会包含小的
模块化的coroutine,以及一个封装函数把每个小的coroutne连接起来。main()用来收集所有的任务，把中心化的
coroutine映射到某个iterable或者pool中。在这个例子中，pool是range(3).

## asycnio设计模式
### chaining coroutines
coroutine的关键特征是他们可以chain在一起。记住，coroutine对象是awaitable的，这样另一个coroutine
可以await.这样可以把程序变成小的可管理的coroutine.

```py

#!/usr/bin/env python3
# chained.py

import asyncio
import random
import time

async def part1(n: int) -> str:
    i = random.randint(0, 10)
    print(f"part1({n}) sleeping for {i} seconds.")
    await asyncio.sleep(i)
    result = f"result{n}-1"
    print(f"Returning part1({n}) == {result}.")
    return result

async def part2(n: int, arg: str) -> str:
    i = random.randint(0, 10)
    print(f"part2{n, arg} sleeping for {i} seconds.")
    await asyncio.sleep(i)
    result = f"result{n}-2 derived from {arg}"
    print(f"Returning part2{n, arg} == {result}.")
    return result

async def chain(n: int) -> None:
    start = time.perf_counter()
    p1 = await part1(n)
    p2 = await part2(n, p1)
    end = time.perf_counter() - start
    print(f"-->Chained result{n} => {p2} (took {end:0.2f} seconds).")

async def main(*args):
    await asyncio.gather(*(chain(n) for n in args))

if __name__ == "__main__":
    import sys
    random.seed(444)
    args = [1, 2, 3] if len(sys.argv) == 1 else map(int, sys.argv[1:])
    start = time.perf_counter()
    asyncio.run(main(*args))
    end = time.perf_counter() - start
    print(f"Program finished in {end:0.2f} seconds.")
```
注意这段程序的输出，当part1()sleep一段时间的时候，part2()开始处理结果直到它们可用。

```
$ python3 chained.py 9 6 3
part1(9) sleeping for 4 seconds.
part1(6) sleeping for 4 seconds.
part1(3) sleeping for 0 seconds.
Returning part1(3) == result3-1.
part2(3, 'result3-1') sleeping for 4 seconds.
Returning part1(9) == result9-1.
part2(9, 'result9-1') sleeping for 7 seconds.
Returning part1(6) == result6-1.
part2(6, 'result6-1') sleeping for 4 seconds.
Returning part2(3, 'result3-1') == result3-2 derived from result3-1.
-->Chained result3 => result3-2 derived from result3-1 (took 4.00 seconds).
Returning part2(6, 'result6-1') == result6-2 derived from result6-1.
-->Chained result6 => result6-2 derived from result6-1 (took 8.01 seconds).
Returning part2(9, 'result9-1') == result9-2 derived from result9-1.
-->Chained result9 => result9-2 derived from result9-1 (took 11.01 seconds).
Program finished in 11.01 seconds.
```
这种情况下main()的运行时间等于任务的最大运行时间。

### 使用queue
async包提供了类似于queue模块的queue类。目前还没有用到queue结构体，在chain.py中，每个
任务(future)由coroutine集合构成。

还有一种结构体可以用在async IO中，一些互相没有关联的生产者将items添加到队列。每个生产者
可能交错的、随机的、或者任意时间添加多个项给队列。一组消费者出现后从队列中不会等待其他信号
从队列中提取items.

这种设计中不会把消费者和生产者chain在一起。消费者不知道生产者的数量甚至添加到队列中的items
的累计数量。队列提供了一个途径让生产者和消费者不直接交互的情况下互相通信。

:::note
尽管队列经常用在多线程程序中，出于queue.Queue()的线程安全的考虑，在asyncio中不需要考虑线程
安全。
:::

同步版本的这个程序看上去比较差，一组阻塞的生产者顺序的给队列添加items,每次一个生产者，所有的生产者完成之后，队列
才能被处理，消费者每次一个item处理，这回导致海量的延迟。

在异步版本中asyncq.py,如下面的代码。这个工作流麻烦的地方是需要给消费者一个信号表示生产完成。否则，
await q.get()会永远挂起，因为队列将被完全处理，但是消费者不知道生产已经完成。

关键是await q.join()，会阻塞直到队列中的所有items都被接受和处理，然后取消消费者，不然会挂起并无线等待items出现。


```py
#!/usr/bin/env python3
# asyncq.py

import asyncio
import itertools as it
import os
import random
import time

async def makeitem(size: int = 5) -> str:
    return os.urandom(size).hex()

async def randsleep(caller=None) -> None:
    i = random.randint(0, 10)
    if caller:
        print(f"{caller} sleeping for {i} seconds.")
    await asyncio.sleep(i)

async def produce(name: int, q: asyncio.Queue) -> None:
    n = random.randint(0, 10)
    for _ in it.repeat(None, n):  # Synchronous loop for each single producer
        await randsleep(caller=f"Producer {name}")
        i = await makeitem()
        t = time.perf_counter()
        await q.put((i, t))
        print(f"Producer {name} added <{i}> to queue.")

async def consume(name: int, q: asyncio.Queue) -> None:
    while True:
        await randsleep(caller=f"Consumer {name}")
        i, t = await q.get()
        now = time.perf_counter()
        print(f"Consumer {name} got element <{i}>"
              f" in {now-t:0.5f} seconds.")
        q.task_done()

async def main(nprod: int, ncon: int):
    q = asyncio.Queue()
    producers = [asyncio.create_task(produce(n, q)) for n in range(nprod)]
    consumers = [asyncio.create_task(consume(n, q)) for n in range(ncon)]
    await asyncio.gather(*producers)
    await q.join()  # Implicitly awaits consumers, too
    for c in consumers:
        c.cancel()

if __name__ == "__main__":
    import argparse
    random.seed(444)
    parser = argparse.ArgumentParser()
    parser.add_argument("-p", "--nprod", type=int, default=5)
    parser.add_argument("-c", "--ncon", type=int, default=10)
    ns = parser.parse_args()
    start = time.perf_counter()
    asyncio.run(main(**ns.__dict__))
    elapsed = time.perf_counter() - start
    print(f"Program completed in {elapsed:0.5f} seconds.")
```
The first few coroutines are helper functions that return a random string, a fractional-second performance counter, and a random integer. A producer puts anywhere from 1 to 5 items into the queue. Each item is a tuple of (i, t) where i is a random string and t is the time at which the producer attempts to put the tuple into the queue.

When a consumer pulls an item out, it simply calculates the elapsed time that the item sat in the queue using the timestamp that the item was put in with.

Keep in mind that asyncio.sleep() is used to mimic some other, more complex coroutine that would eat up time and block all other execution if it were a regular blocking function.

Here is a test run with two producers and five consumers:

```
$ python3 asyncq.py -p 2 -c 5
Producer 0 sleeping for 3 seconds.
Producer 1 sleeping for 3 seconds.
Consumer 0 sleeping for 4 seconds.
Consumer 1 sleeping for 3 seconds.
Consumer 2 sleeping for 3 seconds.
Consumer 3 sleeping for 5 seconds.
Consumer 4 sleeping for 4 seconds.
Producer 0 added <377b1e8f82> to queue.
Producer 0 sleeping for 5 seconds.
Producer 1 added <413b8802f8> to queue.
Consumer 1 got element <377b1e8f82> in 0.00013 seconds.
Consumer 1 sleeping for 3 seconds.
Consumer 2 got element <413b8802f8> in 0.00009 seconds.
Consumer 2 sleeping for 4 seconds.
Producer 0 added <06c055b3ab> to queue.
Producer 0 sleeping for 1 seconds.
Consumer 0 got element <06c055b3ab> in 0.00021 seconds.
Consumer 0 sleeping for 4 seconds.
Producer 0 added <17a8613276> to queue.
Consumer 4 got element <17a8613276> in 0.00022 seconds.
Consumer 4 sleeping for 5 seconds.
Program completed in 9.00954 seconds.

```
In this case, the items process in fractions of a second. A delay can be due to two reasons:

Standard, largely unavoidable overhead
Situations where all consumers are sleeping when an item appears in the queue
With regards to the second reason, luckily, it is perfectly normal to scale to hundreds or thousands of consumers. You should have no problem with python3 asyncq.py -p 5 -c 100. The point here is that, theoretically, you could have different users on different systems controlling the management of producers and consumers, with the queue serving as the central throughput.

So far, you’ve been thrown right into the fire and seen three related examples of asyncio calling coroutines defined with async and await. If you’re not completely following or just want to get deeper into the mechanics of how modern coroutines came to be in Python, you’ll start from square one with the next section.

## asyncio's roots in generators
在前面我们看到过一个旧式的基于生成器的coroutine,尽管有一些过时但是值得再回顾:

```py
import asyncio

@asyncio.coroutine
def py34_coro():
    """Generator-based coroutine"""
    # No need to build these yourself, but be aware of what they are
    s = yield from stuff()
    return s

async def py35_coro():
    """Native coroutine, modern syntax"""
    s = await stuff()
    return s

async def stuff():
    return 0x10, 0x20, 0x30

```
在不使用await或者asycio.run()或者其他asyncio提供的函数的情况下调用py34_coro或者py35_coro会发生什么?
结果会返回一个coroutine对象。小问题:python的什么语言特征也有类似情况?(那个语言特征在调用自身的时候不会做一些实际的任务?)

generator是一个答案,因为coroutine本身就是增强的generator.

```py
>>> def gen():
...     yield 0x10, 0x20, 0x30
...
>>> g = gen()
>>> g  # Nothing much happens - need to iterate with `.__next__()`
<generator object gen at 0x1012705e8>
>>> next(g)
(16, 32, 48)
```

generator函数是asyncio的基础(无论是用async def还是@asyncio.coroutine装饰器),await更接近于yield from而不是yield.

generator的一个关键特征是可以中止并重启,比如在generator对象上break然后之后从剩下的值上resume.当生成器函数到达yield时,
yield这个值然后就会空闲直到要yield下一个值。

```py
>>> from itertools import cycle
>>> def endless():
...     """Yields 9, 8, 7, 6, 9, 8, 7, 6, ... forever"""
...     yield from cycle((9, 8, 7, 6))

>>> e = endless()
>>> total = 0
>>> for i in e:
...     if total < 30:
...         print(i, end=" ")
...         total += i
...     else:
...         print()
...         # Pause execution. We can resume later.
...         break
9 8 7 6 9 8 7 6 9 8 7 6 9 8

>>> # Resume
>>> next(e), next(e), next(e)
(6, 9, 8)
```

await关键字有类似的功能,在coroutine中止的地方打一个断点,这意味着临时移交控制但是没有完全终止。
这就是函数和generator的区别,函数是 all or nothing,一旦启动在return之前不会停止,然后把值返回
给调用方。generator,在到达yield的时候就停止,不仅可以把值返回给调用栈,也可以保存一份本地变量,
这样在其上调用next()的时候可以进行恢复.

generator还有一个更少为人知的特征,可以通过.send()方法把值送给generator,这样generator可以互相调用
而不会相互阻塞。

有一些资源可以辅助理解:

- https://peps.python.org/pep-0342/
- https://snarky.ca/how-the-heck-does-async-await-work-in-python-3-5/
- https://pymotw.com/3/asyncio/coroutines.html
- https://www.dabeaz.com/courses.html


### async for 和async generator+comprehension

除了普通的async/await,python还有async for用来在异步迭代器中迭代。
异步迭代器的目标是在迭代的时候调用异步代码。对应的概念就是异步迭代器,在原生的coroutine
中可以使用await, return或者yield:
```py
>>> async def mygen(u: int = 10):
...     """Yield powers of 2."""
...     i = 0
...     while i < u:
...         yield 2 ** i
...         i += 1
...         await asyncio.sleep(0.1)
```

```py
>>> async def main():
...     # This does *not* introduce concurrent execution
...     # It is meant to show syntax only
...     g = [i async for i in mygen()]
...     f = [j async for j in mygen() if not (j // 3 % 5)]
...     return g, f
...
>>> g, f = asyncio.run(main())
>>> g
[1, 2, 4, 8, 16, 32, 64, 128, 256, 512]
>>> f
[1, 2, 16, 32, 256, 512]

```
注意，既不是异步生成器也不是comprehension让这个iter实现并发,这里只是提供了跟同步版本类似的形式，但是可以让循环放弃控制权，这样让
事件循环运行其他coroutine.

换句话说，异步的iterator和异步的generator不是设计用来并行的将某个函数map到一个序列或者iter上，只是让coroutine移交控制权，这样其他任务
可以运行。async for 和async with只用在普通的for或者with会破坏await的情况下。

### 事件循环和asyncio.run()

事件循环可以理解为监控coroutine的while True循环，从空闲的coroutine上拿到反馈，同时找能运行的coroutine.
事件循环的管理可以隐式的用一个函数调用:
```py
asyncio.run(main())  # Python 3.7+
```
asyncio.run从3.7引入，可以获得事件循环，运行任务直到完成然后关闭事件循环。有一个事件循环更长的写法:
```py
loop = asyncio.get_event_loop()
try:
    loop.run_until_complete(main())
finally:
    loop.close()
```
除非要微调事件循环，不然asyncio.run()就满足大部分要求。如果需要和事件循环进行交互，loop是一个很好的旧式对象可以使用
loop.is_running和loop.is_closed()来自检。在需要更精细的控制时可以操作这个对象，比如需要给循环一个参数来调度回调。

下面有一些关于事件循环的点:

1. coroutine在绑定到事件循环之前不会产生很多行为。

```py
import asyncio

async def main():
    print("Hello ...")
    await asyncio.sleep(1)
    print("World!")

routine = main()
routine
```
需要使用asyncio.run()来实际的调度main() coroutine(future对象)在事件循环中实际执行:
```py
>>> asyncio.run(routine)
Hello ...
World!
```
其他的coroutine也可以用await执行，经常见到的是把main()封装在asyncio.run()然后把coroutine
用await chain在一块调用。

2. 默认情况下，asyncio事件循环运行在单线程单cpu上，这样会更加高效，也可以在多个核心上运行事件循环，比如:https://www.youtube.com/watch?v=0kXaLh8Fz3k&t=630s

3. 事件循环时可插拔的,可以自己写一个事件循环实现然后让他运行tasks.可以查看uvloop包，Cython中实现的实现循环

asyncio包本身有两个事件循环实现:https://docs.python.org/3/library/asyncio-eventloop.html#event-loop-implementations
默认是使用selector模块。



## async request

## context 中的asyncio